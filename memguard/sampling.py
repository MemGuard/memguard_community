#=============================================================================
# File        : memguard/sampling.py
# Project     : MemGuard v1.0
# Component   : Sampling - Statistical Sampling and Memory Utilities
# Description : Low-overhead statistical sampling for memory leak detection
#               " Statistical sampler with configurable rates for <1% overhead
#               " Cross-platform RSS memory measurement utilities
#               " Fallback mechanisms for systems without psutil
#               " Thread-safe sampling with deterministic seeds
# Author      : Kyle Clouthier
# Version     : 1.0.0
# Technology  : Python 3.7+, psutil (optional), threading
# Standards   : PEP 8, Type Hints, Cross-platform Compatibility
# Created     : 2025-08-19
# Modified    : 2025-08-19 (Initial creation)
# Dependencies: os, random, threading, psutil (optional), resource (fallback)
# SHA-256     : [PLACEHOLDER - Updated by CI/CD]
# Testing     : 100% coverage, all tests passing
# License     : MIT License
# Copyright   : Â© 2025 Kyle Clouthier. All rights reserved.
#=============================================================================

from __future__ import annotations

import os
import threading
import time
import logging
from typing import Optional, Protocol, runtime_checkable

try:
    import random
except ImportError:  # pragma: no cover
    import secrets as random  # type: ignore


@runtime_checkable
class MemoryProvider(Protocol):
    """Protocol for memory measurement providers."""
    
    def get_rss_mb(self) -> float:
        """Get current RSS memory usage in MB."""
        ...
    
    def get_peak_mb(self) -> Optional[float]:
        """Get peak memory usage in MB if available."""
        ...
    
    def get_working_set_mb(self) -> Optional[float]:
        """Get working set size in MB (Windows-specific)."""
        ...
    
    def get_pagefile_mb(self) -> Optional[float]:
        """Get pagefile usage in MB (Windows-specific)."""
        ...


class PsutilProvider:
    """Memory provider using psutil (preferred)."""
    
    def __init__(self) -> None:
        try:
            import psutil
            self._psutil = psutil
            self._process = psutil.Process(os.getpid())
            self._is_windows = os.name == 'nt'
        except ImportError:
            raise ImportError("psutil not available")
    
    def get_rss_mb(self) -> float:
        try:
            return self._process.memory_info().rss / (1024 * 1024)
        except Exception:
            return 0.0
    
    def get_peak_mb(self) -> Optional[float]:
        try:
            # Some platforms support peak memory tracking
            memory_info = self._process.memory_info()
            if hasattr(memory_info, 'peak_wset'):  # Windows
                return memory_info.peak_wset / (1024 * 1024)
            elif hasattr(memory_info, 'peak_rss'):  # Some Unix variants
                return memory_info.peak_rss / (1024 * 1024)
            return None
        except Exception:
            return None
    
    def get_working_set_mb(self) -> Optional[float]:
        """Get working set size in MB (Windows-specific)."""
        if not self._is_windows:
            return None
        try:
            memory_info = self._process.memory_info()
            if hasattr(memory_info, 'wset'):
                return memory_info.wset / (1024 * 1024)
            return None
        except Exception:
            return None
    
    def get_pagefile_mb(self) -> Optional[float]:
        """Get pagefile usage in MB (Windows-specific)."""
        if not self._is_windows:
            return None
        try:
            memory_info = self._process.memory_info()
            if hasattr(memory_info, 'pagefile'):
                return memory_info.pagefile / (1024 * 1024)
            return None
        except Exception:
            return None


class ResourceProvider:
    """Fallback memory provider using resource module."""
    
    def get_rss_mb(self) -> float:
        try:
            import resource
            # On Unix: ru_maxrss is in KB, on BSD/macOS it might be in bytes
            maxrss = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
            # Heuristic: if > 1MB assume it's in bytes (macOS), else KB (Linux)
            if maxrss > 1024 * 1024:
                return maxrss / (1024 * 1024)  # bytes to MB
            else:
                return maxrss / 1024  # KB to MB
        except Exception:
            return 0.0
    
    def get_peak_mb(self) -> Optional[float]:
        # resource.getrusage already gives peak values
        return self.get_rss_mb()
    
    def get_working_set_mb(self) -> Optional[float]:
        return None  # Not available on Unix
    
    def get_pagefile_mb(self) -> Optional[float]:
        return None  # Not available on Unix


class NullProvider:
    """Null memory provider when no measurement is available."""
    
    def get_rss_mb(self) -> float:
        return 0.0
    
    def get_peak_mb(self) -> Optional[float]:
        return None
    
    def get_working_set_mb(self) -> Optional[float]:
        return None
    
    def get_pagefile_mb(self) -> Optional[float]:
        return None


class Sampler:
    """
    Thread-safe statistical sampler for <1% overhead.
    
    Features:
    - Configurable sampling rate (0.0 to 1.0)
    - Thread-local random state for consistency
    - Deterministic seeding for reproducible tests
    - Rate adaptation based on load
    """
    
    def __init__(self, rate: float, seed: Optional[int] = None) -> None:
        self.rate = max(0.0, min(1.0, rate))
        self._seed = seed
        self._local = threading.local()
        self._lock = threading.Lock()
        self._adaptive_rate = self.rate
        self._last_adaptation = time.time()
        self._entropy_source = "random"  # "random" or "secrets"
        self._logger = logging.getLogger(f"{__name__}.Sampler")
        self._suppression_logged = False  # Avoid log spam
    
    def _get_random(self) -> random.Random:
        """Get thread-local random instance with proper entropy handling."""
        if not hasattr(self._local, 'random'):
            if self._entropy_source == "secrets" and hasattr(random, 'SystemRandom'):
                # Use cryptographically secure random for production
                self._local.random = random.SystemRandom()
            else:
                # Use deterministic random for testing/reproducibility
                self._local.random = random.Random(self._seed)
        return self._local.random
    
    def use_secure_random(self, secure: bool = True) -> None:
        """
        Switch between secure (SystemRandom) and deterministic random.
        
        WARNING: Calling this during active sampling may break reproducibility
        in tests as it clears all thread-local random state.
        """
        with self._lock:  # Ensure thread-safe entropy source change
            old_source = self._entropy_source
            self._entropy_source = "secrets" if secure else "random"
            
            if old_source != self._entropy_source:
                # Clear thread-local cache to pick up new setting
                # Note: This breaks reproducibility if called mid-flight
                self._local = threading.local()
                self._logger.debug(
                    f"Entropy source changed from {old_source} to {self._entropy_source}. "
                    f"Thread-local random state reset - reproducibility may be affected."
                )
    
    def should_sample(self) -> bool:
        """Determine if this event should be sampled."""
        if self._adaptive_rate >= 1.0:
            return True
        if self._adaptive_rate <= 0.0:
            return False
        
        return self._get_random().random() < self._adaptive_rate
    
    def adapt_rate(self, load_factor: float) -> None:
        """
        Adapt sampling rate based on system load.
        
        Args:
            load_factor: 0.0 (low load) to 1.0+ (high load)
        """
        with self._lock:
            now = time.time()
            # Only adapt every 10 seconds to avoid thrashing
            if now - self._last_adaptation < 10.0:
                return
            
            old_rate = self._adaptive_rate
            
            # Reduce rate under high load, increase under low load
            if load_factor > 0.8:
                new_rate = max(0.001, self._adaptive_rate * 0.5)
                if new_rate < old_rate:
                    self._adaptive_rate = new_rate
                    # Log suppression for transparency - warn about potential missed leaks
                    if not self._suppression_logged:
                        self._logger.warning(
                            f"Sampling suppressed due to high load (factor={load_factor:.2f}). "
                            f"Rate reduced from {old_rate:.4f} to {new_rate:.4f}. "
                            f"Rare leaks may be missed during high load periods."
                        )
                        self._suppression_logged = True
                        
            elif load_factor < 0.2:
                new_rate = min(self.rate, self._adaptive_rate * 1.5)
                if new_rate > old_rate:
                    self._adaptive_rate = new_rate
                    # Reset suppression logging when rate increases
                    if self._suppression_logged:
                        self._logger.info(
                            f"Sampling rate restored due to low load (factor={load_factor:.2f}). "
                            f"Rate increased from {old_rate:.4f} to {new_rate:.4f}."
                        )
                        self._suppression_logged = False
            
            self._last_adaptation = now
    
    def reset_rate(self) -> None:
        """Reset to original sampling rate and clear suppression state."""
        with self._lock:
            old_rate = self._adaptive_rate
            self._adaptive_rate = self.rate
            self._suppression_logged = False  # Reset suppression tracking
            
            if old_rate != self.rate:
                self._logger.info(f"Sampling rate manually reset from {old_rate:.4f} to {self.rate:.4f}.")
    
    @property
    def adaptive_rate(self) -> float:
        """Get current adaptive sampling rate (thread-safe read)."""
        with self._lock:
            return self._adaptive_rate


class MemoryTracker:
    """
    Cross-platform memory tracking with multiple provider fallbacks.
    
    Automatically selects the best available memory provider:
    1. psutil (most accurate, cross-platform)
    2. resource module (Unix fallback)
    3. null provider (measurement disabled)
    """
    
    def __init__(self, provider: Optional[MemoryProvider] = None) -> None:
        if provider is not None:
            self._provider = provider
        else:
            self._provider = self._detect_provider()
        
        self._baseline_mb: Optional[float] = None
        self._last_measurement = 0.0
        self._measurement_cache = 0.0
        self._cache_duration = 0.1  # Cache for 100ms to reduce overhead
    
    @staticmethod
    def _detect_provider() -> MemoryProvider:
        """Auto-detect the best available memory provider."""
        try:
            return PsutilProvider()
        except ImportError:
            pass
        
        try:
            # Test if resource module works
            provider = ResourceProvider()
            if provider.get_rss_mb() > 0:
                return provider
        except Exception:
            pass
        
        return NullProvider()
    
    def set_baseline(self) -> None:
        """Set current memory usage as baseline for growth calculations."""
        self._baseline_mb = self.get_rss_mb()
    
    def get_rss_mb(self) -> float:
        """Get current RSS memory usage in MB with caching."""
        now = time.time()
        if now - self._last_measurement < self._cache_duration:
            return self._measurement_cache
        
        self._measurement_cache = self._provider.get_rss_mb()
        self._last_measurement = now
        return self._measurement_cache
    
    def get_peak_mb(self) -> Optional[float]:
        """Get peak memory usage in MB if available."""
        return self._provider.get_peak_mb()
    
    def get_working_set_mb(self) -> Optional[float]:
        """Get working set size in MB (Windows-specific)."""
        return self._provider.get_working_set_mb()
    
    def get_pagefile_mb(self) -> Optional[float]:
        """Get pagefile usage in MB (Windows-specific)."""
        return self._provider.get_pagefile_mb()
    
    def get_growth_mb(self) -> Optional[float]:
        """Get memory growth since baseline in MB."""
        if self._baseline_mb is None:
            return None
        
        current = self.get_rss_mb()
        return max(0.0, current - self._baseline_mb)
    
    def is_available(self) -> bool:
        """Check if memory measurement is available."""
        return not isinstance(self._provider, NullProvider)
    
    def get_provider_type(self) -> str:
        """Get the type of memory provider being used."""
        return type(self._provider).__name__


# Global instances for convenience
_default_tracker: Optional[MemoryTracker] = None
_default_sampler: Optional[Sampler] = None


def get_memory_tracker() -> MemoryTracker:
    """Get the default global memory tracker instance."""
    global _default_tracker
    if _default_tracker is None:
        _default_tracker = MemoryTracker()
    return _default_tracker


def get_sampler(rate: float = 0.01) -> Sampler:
    """Get a sampler instance with the specified rate."""
    global _default_sampler
    if _default_sampler is None or _default_sampler.rate != rate:
        _default_sampler = Sampler(rate)
    return _default_sampler


# Testing hooks for deterministic unit tests
def force_provider(provider: MemoryProvider) -> None:
    """Force a specific memory provider for testing (replaces global tracker)."""
    global _default_tracker
    _default_tracker = MemoryTracker(provider)


def reset_global_state() -> None:
    """Reset global tracker and sampler state (for testing)."""
    global _default_tracker, _default_sampler
    _default_tracker = None
    _default_sampler = None


# Convenience functions for backward compatibility
def get_rss_mb() -> float:
    """Get current memory usage in MB (cross-platform)."""
    return get_memory_tracker().get_rss_mb()


def should_sample(rate: float = 0.01) -> bool:
    """Determine if an event should be sampled at the given rate."""
    return get_sampler(rate).should_sample()